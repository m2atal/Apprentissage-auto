{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "#from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a few parameters\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST('./data', train=True, download=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor effectue une normalisation min-max.\n",
    "]), )\n",
    "\n",
    "\n",
    "test = MNIST('./data', train=False, download=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor effectue une normalisation min-max.\n",
    "]), )\n",
    "\n",
    "# Cr√©ation du DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a discriminator class\n",
    "This class heritates from the torch.nn.module\n",
    "\n",
    "It implements a FeedForward Neural network with the following architecture:\n",
    "- 3 blocks of:\n",
    "    - linear layer\n",
    "    - leaky relu activation\n",
    "    - dropout\n",
    "- Linear layer\n",
    "- sigmoid function\n",
    "\n",
    "Output sizes of the different linear layers are: 1024, 512, 256, 1\n",
    "\n",
    "Dropout probability is set to 0.3\n",
    "\n",
    "Leakyrelu parameter is set to 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x.view(x.size(0), 784))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Generator class\n",
    "This class heritates from the torch.nn.module\n",
    "\n",
    "It implements a FeedForward Neural network with the following architecture:\n",
    "- 3 blocks of:\n",
    "    - linear layer\n",
    "    - leaky relu activation\n",
    "- Linear layer\n",
    "- Tanh function\n",
    "\n",
    "Output sizes of the different linear layers are: 256, 512, 1024, 784\n",
    "\n",
    "Leakyrelu parameter is set to 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 100)\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send models on the right device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a criterion as binary cross entropy loss\n",
    "* Set learning rate to 0.0002\n",
    "* Define two optimizers: **d_optimizer** and **g_optimizer** for the discriminator and the generator, both use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator training function\n",
    "\n",
    "Write a function which prototype is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels):\n",
    "\n",
    "    return d_loss, real_score, fake_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator training function\n",
    "\n",
    "Write a function which prototype is given below\n",
    "g_loss is computed using the criterion defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(generator, discriminator_outputs, real_labels):\n",
    "\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-efb9d82d4ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# draw samples from the input distribution to inspect the generation on training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_test_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# draw samples from the input distribution to inspect the generation on training \n",
    "num_test_samples = 16\n",
    "test_noise = torch.randn(num_test_samples, 100).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "We now implement the training loop that perform the Discriminator and Generator alternated training.\n",
    "In order to check the progress, we display 16 samples of digits generated by the Generator every 100 batches.\n",
    "\n",
    "The skeleton of the training loop is given below.\n",
    "\n",
    "In this loop we perform training of the discriminateo and generator as follow:\n",
    "- one batch training for discriminator \n",
    "- one batch training for the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "\n",
    "# set number of epochs and initialize figure counter\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "num_fig = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"start epoch: len(train_loader) = {train_loader.__len__()}\")\n",
    "    for n, (images, _) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "          \n",
    "        real_labels = torch.ones((images.size(0), 1)).to(device)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        #    Sample from generator\n",
    "        #        Draw random variables to feed the generator\n",
    "        #        Generate fake images\n",
    "        #        Set the fake labels to ther proper value\n",
    "        #    Train the discriminator \n",
    "\n",
    "        # Sample again from the generator and get output from discriminator\n",
    "\n",
    "\n",
    "        # Train the generator\n",
    "\n",
    "\n",
    "        # Display fake images and compute the losses\n",
    "        if (n+1) % 100 == 0:\n",
    "            test_images = generator(test_noise)\n",
    "            \n",
    "            for k in range(num_test_samples):\n",
    "                i = k//4\n",
    "                j = k%4\n",
    "                ax[i,j].cla()\n",
    "                ax[i,j].imshow(test_images[k,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            plt.savefig('results/mnist-gan-%03d.png'%num_fig)\n",
    "            num_fig += 1\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}\".format(\n",
    "                    epoch + 1, num_epochs, n+1, num_batches, d_loss.data.item(), g_loss.data.item(), \n",
    "                    real_score.data.mean(), fake_score.data.mean()))\n",
    "        \n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
